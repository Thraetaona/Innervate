<div align="center">

  <h1><code>Innervate</code></h1>

  <p>
    <strong>A simple and free-from-overcomplications implementation of artificial neural networks ("ANN") using only Python and NumPy.</strong>
  </p>

  <h3>
    <a href="https://github.com/Thraetaona/Innervate/discussions">Discussions</a>
    <span> | </span>
    <a href="https://github.com/Thraetaona/Innervate/issues">Issue Tracker</a>
    <span> | </span>
    <a href="https://github.com/Thraetaona/Innervate/actions">CI</a>
    <span> | </span>
    <a href="https://github.com/Thraetaona/Innervate/projects">Roadmap</a>
    <span> | </span>
    <a href="https://github.com/Thraetaona/Innervate/releases">Releases</a>
  </h3>
  
</div>

***

## WIP



      Writing the Library from scratch---using only Python and Numpy (for easier matrix algebra without having to use for-loops each time)---taught me what a neural network actually is and how exactly it gets trained.  The vast majority of machine learning courses and material on the Internet, of which there is no shortage, seemed to merely parrot the same Wikipedia-style description of algorithms and concepts used in machine learning; they all treated neural networks as some sort of blackbox where TensorFlow would magically convert our input to an output.  On the other hand, the lectures that did try to dive deeper into the topics seemed to explain them in impractical and overly abstract ways; they would spend hours describing how to take the derivative/gradient matrix of a function (e.g., Sigmoid, Mean Square Root, etc.) without ever explaining the goal, purpose, or motive of doing so.

      In the end, it was piecing together the knowledges gained from various open-sourced machine learning repositories, semi-obscure forum guides, and a few useful YouTube videos that came to my rescue.
